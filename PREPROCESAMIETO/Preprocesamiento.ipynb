{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6kGRQgY4Eer88vOb9na+P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andres54ml/ME02_especializacion/blob/main/PREPROCESAMIETO/Preprocesamiento.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descarga de datos históricos de Bancolombia ADR (CIB)\n",
        "\n",
        "En esta celda se utiliza la librería `yfinance` para descargar el historial de precios de apertura del ADR de Bancolombia (símbolo \"CIB\") desde el 11 de mayo de 2015 hasta el 9 de mayo de 2025. Luego, se filtra únicamente la columna **Open** (precio de apertura) y se reinicia el índice para que la columna de fechas quede como una columna regular del DataFrame.\n"
      ],
      "metadata": {
        "id": "B26w0ZN2f3kd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KA15cagfvlg",
        "outputId": "3c53873c-028a-4251-a578-015fefc0a221"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YF.download() has changed argument auto_adjust default to True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Price        Date       Open\n",
            "Ticker                   CIB\n",
            "0      2015-05-11  22.255103\n",
            "1      2015-05-12  22.114088\n",
            "2      2015-05-13  22.293994\n",
            "3      2015-05-14  22.396111\n",
            "4      2015-05-15  22.279408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "\n",
        "# Descarga histórico de Bancolombia ADR (CIB)\n",
        "df_principal = yf.download(\n",
        "    \"CIB\",\n",
        "    start=\"2015-05-11\",\n",
        "    end=\"2025-05-9\"\n",
        ")\n",
        "\n",
        "# Filtrar solo la columna Open y mover el índice Date a columna\n",
        "df_principal = df_principal[['Open']].reset_index()\n",
        "\n",
        "print(df_principal.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carga y procesamiento de datos externos\n",
        "\n",
        "En esta celda se carga un archivo de Excel que contiene una hoja llamada **\"Datos\"**. Todos los valores se leen como texto (`dtype=str`). Luego:\n",
        "\n",
        "1. Se convierte la columna **Fecha** al formato de fecha (`datetime`), especificando que el día viene primero (formato DD/MM/YYYY).\n",
        "2. Finalmente, se renombra la columna **Fecha** a **Date** para mantener consistencia con otros DataFrames."
      ],
      "metadata": {
        "id": "3B7EzIe6gAqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Lee las dos hojas como texto\n",
        "archivo = \"/content/graficador_series (1) (1).xlsx\"\n",
        "sheets = pd.read_excel(\n",
        "    archivo,\n",
        "    sheet_name=[\"Datos\"],\n",
        "    dtype=str\n",
        ")\n",
        "\n",
        "df_secundario =  sheets[\"Datos\"]\n",
        "\n",
        "# 1) Convertir a datetime, indicando dayfirst para DD/MM/YYYY\n",
        "df_secundario['Fecha'] = pd.to_datetime(\n",
        "    df_secundario['Fecha'],\n",
        "    format=\"%d/%m/%Y\",\n",
        "    dayfirst=True,\n",
        "    errors=\"raise\"\n",
        ")\n",
        "\n",
        "# 2) (Opcional) Si además quieres renombrar la columna a 'Date'\n",
        "df_secundario.rename(columns={'Fecha': 'Date'}, inplace=True)\n"
      ],
      "metadata": {
        "id": "PBDEUQsBgDjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unificación de columnas y combinación de DataFrames\n",
        "\n",
        "- Se renombran las columnas del DataFrame `df_principal` uniendo los niveles con guiones bajos (`_`) en caso de que existan múltiples niveles (MultiIndex).\n",
        "- Luego se asegura que el índice esté reseteado (aunque ya se hizo anteriormente).\n",
        "- Se imprime el número de niveles de columnas tanto para `df_principal` como para `df_secundario`.\n",
        "- Finalmente, se realiza un *merge* (unión) entre `df_principal` y `df_secundario` usando la columna **Date** como clave. Se usa una unión tipo *left join*, conservando todos los registros de `df_principal` y anexando los de `df_secundario` cuando coincidan las fechas."
      ],
      "metadata": {
        "id": "11CU_cBTgHMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Por ejemplo, unir con guión bajo los niveles que haya\n",
        "df_principal.columns = [\n",
        "    \"_\".join(filter(None, col)).strip()\n",
        "    for col in df_principal.columns.values\n",
        "]\n",
        "\n",
        "df_principal = df_principal.reset_index()\n",
        "\n",
        "# print(\"Niveles de columnas en principal:\", df_principal.columns.nlevels)\n",
        "# print(\"Niveles de columnas en secundario:\", df_secundario.columns.nlevels)\n",
        "\n",
        "df_merged = df_principal.merge(\n",
        "    df_secundario,\n",
        "    on='Date',\n",
        "    how='left',\n",
        "    suffixes=('', '_sec')\n",
        ")"
      ],
      "metadata": {
        "id": "Q0PE-nGBgKWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Limpieza de datos: manejo de valores faltantes\n",
        "\n",
        "- Se seleccionan algunas columnas económicas relevantes del DataFrame combinado `df_merged`.\n",
        "- En esas columnas, se reemplazan los valores \"-\" por `NaN` para que pandas los reconozca como datos faltantes.\n",
        "- Finalmente, se imprime la cantidad de valores nulos (`NaN`) en cada una de las columnas seleccionadas, como verificación del reemplazo."
      ],
      "metadata": {
        "id": "Pu-It5mdgNXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "cols = [\n",
        "    \"M1, mensual(Dato fin de mes)\",\n",
        "    \"Inflación total(Dato fin de mes)\",\n",
        "    \"Crecimiento PIB real, Trimestral, base: 2015, Ajuste estacional(Dato fin de trimestre)\",\n",
        "    \"Tasa de desempleo - total nacional(Dato fin de mes)\"\n",
        "]\n",
        "\n",
        "# Reemplaza todos los \"-\" por NaN solo en esas columnas\n",
        "df_merged[cols] = df_merged[cols].replace(\"-\", np.nan)\n",
        "\n",
        "# Comprueba que ahora pandas los reconoce como NaN\n",
        "print(df_merged[cols].isna().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oa40en3cgSuj",
        "outputId": "62465e08-9137-4519-b476-e4fc2cf2e6dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "M1, mensual(Dato fin de mes)                                                              2430\n",
            "Inflación total(Dato fin de mes)                                                          2429\n",
            "Crecimiento PIB real, Trimestral, base: 2015, Ajuste estacional(Dato fin de trimestre)    2489\n",
            "Tasa de desempleo - total nacional(Dato fin de mes)                                       2430\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imputación de valores faltantes en series temporales macroeconómicas\n",
        "\n",
        "Este notebook implementa un flujo completo para limpiar e imputar valores faltantes en variables macroeconómicas de frecuencia mensual y trimestral.\n",
        "\n",
        "---\n",
        "\n",
        "## Objetivo\n",
        "\n",
        "Transformar y completar series de tiempo con valores faltantes (representados como guiones), aplicando técnicas adecuadas de imputación según la naturaleza de cada variable.\n",
        "\n",
        "---\n",
        "\n",
        "## Paso 1: Limpieza de datos\n",
        "\n",
        "- Se reemplazan guiones (`-`, `–`, `—`) por `NaN`, que representan valores faltantes.\n",
        "- Se reemplazan las comas (`,`) por puntos (`.`) para estandarizar el formato decimal.\n",
        "\n",
        "---\n",
        "\n",
        "## Paso 2: Conversión a tipo numérico\n",
        "\n",
        "- Las columnas seleccionadas se convierten a tipo numérico (`float`).\n",
        "- Cualquier valor no convertible se convierte automáticamente a `NaN`.\n",
        "\n",
        "---\n",
        "\n",
        "## Paso 3: Manejo de fechas\n",
        "\n",
        "- Se convierte la columna `Date` a formato `datetime` si existe.\n",
        "- Se establece como índice del DataFrame para facilitar la imputación temporal.\n",
        "- Se ordena cronológicamente el índice.\n",
        "\n",
        "---\n",
        "\n",
        "## Paso 3.5: Verificación previa\n",
        "\n",
        "- Se imprime el número de valores nulos por columna antes de la imputación.\n",
        "- Se visualizan las primeras filas para inspección rápida del estado de los datos.\n",
        "\n",
        "---\n",
        "\n",
        "## Paso 4: Imputación de valores faltantes\n",
        "\n",
        "- Para variables con comportamiento suave y continuo (como M1 y desempleo), se usa interpolación temporal (`interpolate(method='time')`) y backfill.\n",
        "- Para variables que cambian de forma más discreta (como inflación y PIB), se usa forward-fill (`fillna(method='ffill')`) seguido de backfill si es necesario.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "PrEr1PTxgYbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "cols = [\n",
        "    'M1, mensual(Dato fin de mes)',\n",
        "    'Inflación total(Dato fin de mes)',\n",
        "    'Crecimiento PIB real, Trimestral, base: 2015, Ajuste estacional(Dato fin de trimestre)',\n",
        "    'Tasa de desempleo - total nacional(Dato fin de mes)'\n",
        "]\n",
        "\n",
        "# --- Paso 1: Limpieza de guiones y conversión de comas a puntos ---\n",
        "# Esto reemplaza posibles representaciones de valores faltantes y ajusta el separador decimal.\n",
        "print(\"Starting data cleaning and conversion...\")\n",
        "df_merged[cols] = (\n",
        "    df_merged[cols]\n",
        "    .replace(r'^\\s*[-–—]\\s*$', np.nan, regex=True) # Reemplaza guiones (cortos, medios, largos) rodeados de espacios por NaN\n",
        "    .replace(',', '.', regex=True) # Reemplaza comas por puntos como separador decimal\n",
        ")\n",
        "print(\"Cleaning and comma replacement complete.\")\n",
        "\n",
        "# --- Paso 2: Conversión a float ---\n",
        "# Convierte las columnas a tipo numérico (float), forzando los errores a NaN.\n",
        "print(\"Converting columns to numeric...\")\n",
        "df_merged[cols] = df_merged[cols].apply(pd.to_numeric, errors='coerce')\n",
        "print(\"Numeric conversion complete.\")\n",
        "\n",
        "# --- Paso 3: Asegurar que la información temporal está en datetime y establecer el índice ---\n",
        "# Convierte la columna o el índice de fecha a tipo datetime y establece el índice si es necesario.\n",
        "print(\"Ensuring datetime index and sorting...\")\n",
        "if 'Date' in df_merged.columns:\n",
        "    # Si 'Date' existe como columna, la convertimos y la establecemos como índice\n",
        "    df_merged['Date'] = pd.to_datetime(df_merged['Date'], errors='coerce')\n",
        "    df_merged = df_merged.set_index('Date')\n",
        "    # Eliminar la columna Date original si ya se convirtió a índice\n",
        "    # if 'Date' in df_merged.columns:\n",
        "    #     df_merged = df_merged.drop(columns=['Date']) # Esto es opcional dependiendo de si Date duplicada\n",
        "else:\n",
        "    # Si la fecha ya está en el índice, solo aseguramos la conversión a datetime\n",
        "    df_merged.index = pd.to_datetime(df_merged.index, errors='coerce')\n",
        "\n",
        "# Ordenar el DataFrame por índice de tiempo\n",
        "df_merged = df_merged.sort_index()\n",
        "print(\"Datetime index set and sorted.\")\n",
        "\n",
        "# --- Paso 3.5: Verificación de NaN después de la limpieza y antes de la imputación ---\n",
        "# Imprime el número de NaN por columna y las primeras filas para inspeccionar los datos antes de imputar.\n",
        "print(\"\\n--- Verification Before Imputation ---\")\n",
        "print(\"NaN counts per column after cleaning and conversion:\")\n",
        "print(df_merged[cols].isnull().sum())\n",
        "print(\"\\nHead of DataFrame (first 10 rows) before imputation:\")\n",
        "print(df_merged[cols].head(10))\n",
        "print(\"------------------------------------\\n\")\n",
        "\n",
        "\n",
        "# --- Paso 4: Imputaciones ---\n",
        "# Rellenar los valores faltantes.\n",
        "# Usamos interpolate(method='time') seguido de fillna(method='bfill') para las series mensuales/diarias.\n",
        "# Usamos fillna(method='ffill') seguido de fillna(method='bfill') para las series trimestrales o donde ffill es más apropiado.\n",
        "# El .fillna(method='bfill') después de la imputación principal se encarga de los NaNs iniciales\n",
        "# (usando el primer valor válido encontrado hacia adelante) y los NaNs finales.\n",
        "print(\"Starting imputation...\")\n",
        "\n",
        "# Series mensuales/diarias: M1, Tasa de Desempleo (interpolación basada en tiempo, luego bfill para iniciales/finales)\n",
        "df_merged['M1, mensual(Dato fin de mes)'] = df_merged['M1, mensual(Dato fin de mes)'].interpolate(method='time').fillna(method='bfill')\n",
        "df_merged['Tasa de desempleo - total nacional(Dato fin de mes)'] = df_merged['Tasa de desempleo - total nacional(Dato fin de mes)'].interpolate(method='time').fillna(method='bfill')\n",
        "\n",
        "# Series mensuales/trimestrales: Inflación, Crecimiento PIB (ffill, luego bfill para iniciales/finales)\n",
        "df_merged['Inflación total(Dato fin de mes)'] = df_merged['Inflación total(Dato fin de mes)'].fillna(method='ffill').fillna(method='bfill')\n",
        "df_merged['Crecimiento PIB real, Trimestral, base: 2015, Ajuste estacional(Dato fin de trimestre)'] = (\n",
        "    df_merged['Crecimiento PIB real, Trimestral, base: 2015, Ajuste estacional(Dato fin de trimestre)']\n",
        "    .fillna(method='ffill')\n",
        "    .fillna(method='bfill')\n",
        ")\n",
        "\n",
        "print(\"Imputation complete.\")\n",
        "\n",
        "# --- Paso 5: Verificación Final ---\n",
        "# Vuelve a verificar si quedan NaNs y muestra las primeras filas después de la imputación.\n",
        "print(\"\\n--- Final Verification After Imputation ---\")\n",
        "print(\"NaN counts per column after imputation:\")\n",
        "print(df_merged[cols].isnull().sum())\n",
        "print(\"\\nHead of DataFrame (first 10 rows) after imputation:\")\n",
        "print(df_merged[cols].head(10))\n",
        "print(\"------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mW2FPJzbgZz6",
        "outputId": "a3f7f403-c944-4cf2-999b-dad7dc83f338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting data cleaning and conversion...\n",
            "Cleaning and comma replacement complete.\n",
            "Converting columns to numeric...\n",
            "Numeric conversion complete.\n",
            "Ensuring datetime index and sorting...\n",
            "Datetime index set and sorted.\n",
            "\n",
            "--- Verification Before Imputation ---\n",
            "NaN counts per column after cleaning and conversion:\n",
            "M1, mensual(Dato fin de mes)                                                              2430\n",
            "Inflación total(Dato fin de mes)                                                          2429\n",
            "Crecimiento PIB real, Trimestral, base: 2015, Ajuste estacional(Dato fin de trimestre)    2489\n",
            "Tasa de desempleo - total nacional(Dato fin de mes)                                       2430\n",
            "dtype: int64\n",
            "\n",
            "Head of DataFrame (first 10 rows) before imputation:\n",
            "            M1, mensual(Dato fin de mes)  Inflación total(Dato fin de mes)  \\\n",
            "Date                                                                         \n",
            "2015-05-11                           NaN                               NaN   \n",
            "2015-05-12                           NaN                               NaN   \n",
            "2015-05-13                           NaN                               NaN   \n",
            "2015-05-14                           NaN                               NaN   \n",
            "2015-05-15                           NaN                               NaN   \n",
            "2015-05-18                           NaN                               NaN   \n",
            "2015-05-19                           NaN                               NaN   \n",
            "2015-05-20                           NaN                               NaN   \n",
            "2015-05-21                           NaN                               NaN   \n",
            "2015-05-22                           NaN                               NaN   \n",
            "\n",
            "            Crecimiento PIB real, Trimestral, base: 2015, Ajuste estacional(Dato fin de trimestre)  \\\n",
            "Date                                                                                                 \n",
            "2015-05-11                                                NaN                                        \n",
            "2015-05-12                                                NaN                                        \n",
            "2015-05-13                                                NaN                                        \n",
            "2015-05-14                                                NaN                                        \n",
            "2015-05-15                                                NaN                                        \n",
            "2015-05-18                                                NaN                                        \n",
            "2015-05-19                                                NaN                                        \n",
            "2015-05-20                                                NaN                                        \n",
            "2015-05-21                                                NaN                                        \n",
            "2015-05-22                                                NaN                                        \n",
            "\n",
            "            Tasa de desempleo - total nacional(Dato fin de mes)  \n",
            "Date                                                             \n",
            "2015-05-11                                                NaN    \n",
            "2015-05-12                                                NaN    \n",
            "2015-05-13                                                NaN    \n",
            "2015-05-14                                                NaN    \n",
            "2015-05-15                                                NaN    \n",
            "2015-05-18                                                NaN    \n",
            "2015-05-19                                                NaN    \n",
            "2015-05-20                                                NaN    \n",
            "2015-05-21                                                NaN    \n",
            "2015-05-22                                                NaN    \n",
            "------------------------------------\n",
            "\n",
            "Starting imputation...\n",
            "Imputation complete.\n",
            "\n",
            "--- Final Verification After Imputation ---\n",
            "NaN counts per column after imputation:\n",
            "M1, mensual(Dato fin de mes)                                                              0\n",
            "Inflación total(Dato fin de mes)                                                          0\n",
            "Crecimiento PIB real, Trimestral, base: 2015, Ajuste estacional(Dato fin de trimestre)    0\n",
            "Tasa de desempleo - total nacional(Dato fin de mes)                                       0\n",
            "dtype: int64\n",
            "\n",
            "Head of DataFrame (first 10 rows) after imputation:\n",
            "            M1, mensual(Dato fin de mes)  Inflación total(Dato fin de mes)  \\\n",
            "Date                                                                         \n",
            "2015-05-11                        90.429                              4.42   \n",
            "2015-05-12                        90.429                              4.42   \n",
            "2015-05-13                        90.429                              4.42   \n",
            "2015-05-14                        90.429                              4.42   \n",
            "2015-05-15                        90.429                              4.42   \n",
            "2015-05-18                        90.429                              4.42   \n",
            "2015-05-19                        90.429                              4.42   \n",
            "2015-05-20                        90.429                              4.42   \n",
            "2015-05-21                        90.429                              4.42   \n",
            "2015-05-22                        90.429                              4.42   \n",
            "\n",
            "            Crecimiento PIB real, Trimestral, base: 2015, Ajuste estacional(Dato fin de trimestre)  \\\n",
            "Date                                                                                                 \n",
            "2015-05-11                                               3.47                                        \n",
            "2015-05-12                                               3.47                                        \n",
            "2015-05-13                                               3.47                                        \n",
            "2015-05-14                                               3.47                                        \n",
            "2015-05-15                                               3.47                                        \n",
            "2015-05-18                                               3.47                                        \n",
            "2015-05-19                                               3.47                                        \n",
            "2015-05-20                                               3.47                                        \n",
            "2015-05-21                                               3.47                                        \n",
            "2015-05-22                                               3.47                                        \n",
            "\n",
            "            Tasa de desempleo - total nacional(Dato fin de mes)  \n",
            "Date                                                             \n",
            "2015-05-11                                                8.5    \n",
            "2015-05-12                                                8.5    \n",
            "2015-05-13                                                8.5    \n",
            "2015-05-14                                                8.5    \n",
            "2015-05-15                                                8.5    \n",
            "2015-05-18                                                8.5    \n",
            "2015-05-19                                                8.5    \n",
            "2015-05-20                                                8.5    \n",
            "2015-05-21                                                8.5    \n",
            "2015-05-22                                                8.5    \n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-0a3dad6b073a>:64: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df_merged['M1, mensual(Dato fin de mes)'] = df_merged['M1, mensual(Dato fin de mes)'].interpolate(method='time').fillna(method='bfill')\n",
            "<ipython-input-6-0a3dad6b073a>:65: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df_merged['Tasa de desempleo - total nacional(Dato fin de mes)'] = df_merged['Tasa de desempleo - total nacional(Dato fin de mes)'].interpolate(method='time').fillna(method='bfill')\n",
            "<ipython-input-6-0a3dad6b073a>:68: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df_merged['Inflación total(Dato fin de mes)'] = df_merged['Inflación total(Dato fin de mes)'].fillna(method='ffill').fillna(method='bfill')\n",
            "<ipython-input-6-0a3dad6b073a>:71: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  .fillna(method='ffill')\n",
            "<ipython-input-6-0a3dad6b073a>:72: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  .fillna(method='bfill')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 2: Escalado de datos\n",
        "\n",
        "- Se combinan las columnas de entrada y la columna objetivo para aplicar un escalado conjunto.\n",
        "- Se utiliza `MinMaxScaler` para escalar los valores entre 0 y 1.\n",
        "- Esto asegura que todas las variables estén en la misma escala, lo cual es importante para el entrenamiento de redes neuronales.\n",
        "\n",
        "---\n",
        "\n",
        "## Paso 3: Separación de datos escalados\n",
        "\n",
        "- Se identifican los índices de las variables de entrada y del objetivo dentro del array escalado.\n",
        "- Se separan los datos escalados en:\n",
        "  - `training_set_scaled`: datos de entrada multivariados.\n",
        "  - `y_data_scaled`: columna objetivo ya escalada.\n",
        "\n",
        "---\n",
        "\n",
        "## Paso 4: Construcción de secuencias para entrenamiento\n",
        "\n",
        "- Se utiliza una ventana deslizante de tamaño `window_size` para construir las secuencias de entrada.\n",
        "- Cada entrada (`X_train`) es una secuencia de longitud fija con múltiples variables.\n",
        "- Cada etiqueta (`y_train`) es el valor de la variable objetivo inmediatamente después de la ventana.\n",
        "\n",
        "---\n",
        "\n",
        "## Paso 5: Conversión a arrays NumPy\n",
        "\n",
        "- Las listas `X_train` y `y_train` se convierten en arrays NumPy.\n",
        "- Esto es necesario para alimentar estos datos al modelo RNN.\n",
        "\n",
        "---\n",
        "\n",
        "## Verificación final\n",
        "\n",
        "- Se imprime la forma de `X_train` y `y_train` para confirmar que el formato es el adecuado para el entrenamiento.\n",
        "  - `X_train`: (número de secuencias, tamaño de ventana, número de variables).\n",
        "  - `y_train`: (número de secuencias,).\n",
        "\n",
        "---\n",
        "\n",
        "Este preprocesamiento deja los datos listos para ser usados como entrada en una red LSTM o GRU multivariada."
      ],
      "metadata": {
        "id": "eIgDKu4ggdZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# --- Define las columnas ---\n",
        "input_cols = [\n",
        "    'Open_CIB',\n",
        "    # 'M1, mensual(Dato fin de mes)',\n",
        "    'Inflación total(Dato fin de mes)'\n",
        "    # Agrega aquí otras columnas si las deseas usar como input\n",
        "]\n",
        "\n",
        "target_col = 'Open_CIB'  # Columna objetivo (puedes cambiarla)\n",
        "\n",
        "# --- Preparación de los datos ---\n",
        "columns_to_scale = input_cols + ([target_col] if target_col not in input_cols else [])\n",
        "data_to_scale = df_merged[columns_to_scale].values  # Asegúrate de que df_merged esté definido\n",
        "\n",
        "# --- Escalado ---\n",
        "print(\"Starting data scaling...\")\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(data_to_scale)\n",
        "print(\"Data scaling complete.\")\n",
        "\n",
        "# Identificación de índices\n",
        "input_indices = [columns_to_scale.index(col) for col in input_cols]\n",
        "target_index = columns_to_scale.index(target_col)\n",
        "\n",
        "training_set_scaled = scaled_data[:, input_indices]\n",
        "y_data_scaled = scaled_data[:, target_index]\n",
        "\n",
        "print(\"\\n--- Scaling Results Summary ---\")\n",
        "print(\"Original shape of data used for scaling:\", data_to_scale.shape)\n",
        "print(\"Shape of the scaled data array:\", scaled_data.shape)\n",
        "print(\"Shape of the scaled input features (training_set_scaled):\", training_set_scaled.shape)\n",
        "print(\"Shape of the scaled target variable (y_data_scaled):\", y_data_scaled.shape)\n",
        "print(\"-------------------------------\\n\")\n",
        "\n",
        "# --- Construcción de secuencias (X) y etiquetas (y) ---\n",
        "window_size = 60\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "data_length = len(training_set_scaled)\n",
        "for i in range(window_size, data_length):\n",
        "    X_train.append(training_set_scaled[i - window_size:i, :])\n",
        "    y_train.append(y_data_scaled[i])\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "print(\"\\n--- Multivariate Windowing Results (after scaling) ---\")\n",
        "print(f\"Window Size: {window_size}\")\n",
        "print(\"X_train shape (Sequences):\", X_train.shape)\n",
        "print(\"y_train shape (Labels):\", y_train.shape)\n",
        "print(\"----------------------------------------------------\")\n",
        "\n",
        "# --- Guardar datos como CSV ---\n",
        "df_scaled = pd.DataFrame(scaled_data, columns=columns_to_scale)\n",
        "df_scaled.to_csv(\"datos_escalados.csv\", index=False)\n",
        "\n",
        "df_y_train = pd.DataFrame(y_train, columns=[\"Target_scaled\"])\n",
        "df_y_train.to_csv(\"y_train.csv\", index=False)\n",
        "\n",
        "X_train_flat = X_train.reshape(X_train.shape[0], -1)  # (N, window, features) → (N, window * features)\n",
        "df_X_train = pd.DataFrame(X_train_flat)\n",
        "df_X_train.to_csv(\"X_train_flat.csv\", index=False)\n",
        "\n",
        "print(\"\\n✅ Datos guardados como CSV: 'datos_escalados.csv', 'y_train.csv' y 'X_train_flat.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npYPCHN5gg_z",
        "outputId": "61be4c3b-99d4-4ee7-f2fa-900ef73b534e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting data scaling...\n",
            "Data scaling complete.\n",
            "\n",
            "--- Scaling Results Summary ---\n",
            "Original shape of data used for scaling: (2515, 2)\n",
            "Shape of the scaled data array: (2515, 2)\n",
            "Shape of the scaled input features (training_set_scaled): (2515, 2)\n",
            "Shape of the scaled target variable (y_data_scaled): (2515,)\n",
            "-------------------------------\n",
            "\n",
            "\n",
            "--- Multivariate Windowing Results (after scaling) ---\n",
            "Window Size: 60\n",
            "X_train shape (Sequences): (2455, 60, 2)\n",
            "y_train shape (Labels): (2455,)\n",
            "----------------------------------------------------\n",
            "\n",
            "✅ Datos guardados como CSV: 'datos_escalados.csv', 'y_train.csv' y 'X_train_flat.csv'\n"
          ]
        }
      ]
    }
  ]
}